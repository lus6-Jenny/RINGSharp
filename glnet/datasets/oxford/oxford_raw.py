# Functions and classes operating on a raw Oxford dataset

import numpy as np
import cv2
import os
from typing import List
from torch.utils.data import Dataset, ConcatDataset
from sklearn.neighbors import KDTree
import torch
import random
from glnet.datasets.oxford.utils import read_lidar_poses, in_test_split, in_train_split, find_nearest_ndx, read_ts_file
from glnet.datasets.oxford.velodyne import load_velodyne_raw, load_velodyne_binary, velodyne_raw_to_pointcloud
from glnet.utils.data_utils.point_clouds import PointCloudLoader, PointCloudWithImageLoader
import copy
import numpy as np
import matplotlib.pyplot as plt
from glnet.datasets.oxford.utils import *

BAYER_STEREO = 'gbrg'
BAYER_MONO = 'rggb'

# concantate pointclouds generated by the left and right lidar
def pc_concantate(pc_left, pc_right, extrinsics_dir=os.path.join(os.path.dirname(__file__), 'extrinsics')):
    '''velodyne'''
    with open(os.path.join(extrinsics_dir, 'ins.txt')) as extrinsics_file:
        extrinsics = next(extrinsics_file)
        T_ins_matrix = build_se3_transform([float(x) for x in extrinsics.split(' ')])     
    with open(os.path.join(extrinsics_dir, 'velodyne_left.txt')) as extrinsics_file:
        extrinsics = next(extrinsics_file)
        left_T = build_se3_transform([float(x) for x in extrinsics.split(' ')]) 
        left_T = np.dot(np.linalg.inv(T_ins_matrix), left_T)
    with open(os.path.join(extrinsics_dir, 'velodyne_right.txt')) as extrinsics_file:
        extrinsics = next(extrinsics_file)
        right_T = build_se3_transform([float(x) for x in extrinsics.split(' ')])        
        right_T = np.dot(np.linalg.inv(T_ins_matrix), right_T)

    # transpose pc_left and pc_right
    pc_left = pc_left.transpose(1, 0)
    pc_right = pc_right.transpose(1, 0)
    
    intensity_array = copy.deepcopy(pc_left[3,:])
    pc_left[3,:] = 1
    pc_left_ed = np.dot(left_T, pc_left)  
    pc_left[3,:] = intensity_array
    pc_left_ed[3,:] = intensity_array
    intensity_array = copy.deepcopy(pc_right[3,:])
    pc_right[3,:] = 1
    pc_right_ed = np.dot(right_T, pc_right)  
    pc_right[3,:] = intensity_array
    pc_right_ed[3,:] = intensity_array
    pc_cat = np.concatenate((pc_left_ed, pc_right_ed), axis=1)
    pc_cat = pc_cat.transpose(1, 0)
    pc_cat = np.array(pc_cat, dtype=np.float32)
    
    return pc_cat
    

# load lidar file in oxford radar robotcar dataset
def load_lidar_file_oxford_radar(file_path):
    if os.path.isfile(file_path):
        if 'bin' in file_path:
            lidar_pc_raw = load_velodyne_binary(file_path)
        else:
            ranges, intensities, angles, approximate_timestamps = load_velodyne_raw(file_path)
            lidar_pc_raw = velodyne_raw_to_pointcloud(ranges, intensities, angles)
    else:
        if 'bin' in file_path:
            file_path = file_path.replace('bin', 'png')
            ranges, intensities, angles, approximate_timestamps = load_velodyne_raw(file_path)
            lidar_pc_raw = velodyne_raw_to_pointcloud(ranges, intensities, angles)
        else:
            file_path = file_path.replace('png', 'bin')
            lidar_pc_raw = load_velodyne_binary(file_path)

    lidar_pc_raw = lidar_pc_raw.transpose(1, 0)
    lidar_pc_raw = lidar_pc_raw.astype(np.float32)    
    return lidar_pc_raw


def load_img_file_oxford(filename):
    assert os.path.exists(filename), f'Cannot access image file: {filename}'
    input_image = cv2.imread(filename)
    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
    return input_image


class OxfordPointCloudWithImageLoader(PointCloudWithImageLoader):
    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level.
        self.ground_plane_level = -16.0
        self.remove_ground_plane = False

    def read_pcim(self, file_pathname: list, sph=False, extrinsics_dir=None) -> torch.Tensor:
        # Reads the point cloud without pre-processing
        # Returns Nx4 tensor
        # assert extrinsics_dir is not None, 'need extrinsics_dir param for oxford dataset'

        left_velo_filename = file_pathname[0]
        right_velo_filename = file_pathname[1]
        all_velo_filename = left_velo_filename.replace('velodyne_left', 'velodyne_all')
        all_velo_filename = all_velo_filename.replace('png', 'bin')
        all_velo_folder = all_velo_filename.strip(all_velo_filename.split('/')[-1])
        if not os.path.exists(all_velo_folder):
           os.makedirs(all_velo_folder)
        if os.path.isfile(all_velo_filename):
            pc = load_lidar_file_oxford_radar(all_velo_filename)
        else:
            pc_left = load_lidar_file_oxford_radar(left_velo_filename)
            pc_right = load_lidar_file_oxford_radar(right_velo_filename)
            pc = pc_concantate(pc_left, pc_right)
            pc = np.unique(pc, axis=0) # remove duplicate points
            pc.tofile(all_velo_filename)
            print(f'Generating {all_velo_filename}')
        
        mask = pc[:, 2] > self.ground_plane_level
        pc = pc[mask].astype(np.float32)

        if sph:
            images = [load_img_file_oxford(file_pathname[2].replace('mono_left_rect', 'sph'))]
        else:
            images = [load_img_file_oxford(file_pathname[i]) for i in range(2, 6)]

        return pc[:, :3], images


class OxfordPointCloudLoader(PointCloudLoader):
    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level.
        self.ground_plane_level = -16.0

    def read_pc(self, file_pathname: list, sph=False, extrinsics_dir=None) -> torch.Tensor:
        # Reads the point cloud without pre-processing
        # Returns Nx3 tensor
        # assert extrinsics_dir is not None, 'need extrinsics_dir param for oxford dataset'

        left_velo_filename = file_pathname[0]
        right_velo_filename = file_pathname[1]
        all_velo_filename = left_velo_filename.replace('velodyne_left', 'velodyne_all')
        all_velo_filename = all_velo_filename.replace('png', 'bin')
        all_velo_folder = all_velo_filename.strip(all_velo_filename.split('/')[-1])
        if not os.path.exists(all_velo_folder):
           os.makedirs(all_velo_folder)
        if os.path.isfile(all_velo_filename):
            pc = load_lidar_file_oxford_radar(all_velo_filename)
        else:
            pc_left = load_lidar_file_oxford_radar(left_velo_filename)
            pc_right = load_lidar_file_oxford_radar(right_velo_filename)
            pc = pc_concantate(pc_left, pc_right)
            pc = np.unique(pc, axis=0) # remove duplicate points
            pc.tofile(all_velo_filename)
            print(f'Generating {all_velo_filename}')

        # print(f'min z: {np.min(pc[:, 2])}, max z: {np.max(pc[:, 2])}')
        mask = pc[:, 2] > self.ground_plane_level
        pc = pc[mask].astype(np.float32)

        imgs = None
        return pc[:, :3], imgs


class OxfordSequence(Dataset):
    """
    Dataset returns a point cloud from a train or test split from one sequence from a raw Mulran dataset
    """
    def __init__(self, dataset_root: str, sequence_name: str, split: str, sampling_distance: float = 0.2):
        dataset_root = os.path.expanduser(dataset_root)
        assert os.path.exists(dataset_root), f'Cannot access dataset root: {dataset_root}'
        assert split in ['train', 'test', 'all']

        self.dataset_root = dataset_root
        self.sequence_name = sequence_name
        sequence_path = os.path.join(self.dataset_root, self.sequence_name)
        assert os.path.exists(sequence_path), f'Cannot access sequence: {sequence_path}'

        self.right_lidar_tsfile = os.path.join(sequence_path, 'velodyne_right.timestamps')
        self.mono_left_tsfile = os.path.join(sequence_path, 'mono_left.timestamps')
        self.mono_right_tsfile = os.path.join(sequence_path, 'mono_right.timestamps')
        self.mono_rear_tsfile = os.path.join(sequence_path, 'mono_rear.timestamps')
        self.stereo_tsfile = os.path.join(sequence_path, 'stereo.timestamps')

        self.right_lidar_ts = read_ts_file(self.right_lidar_tsfile)    
        self.mono_left_ts = read_ts_file(self.mono_left_tsfile)
        self.mono_right_ts = read_ts_file(self.mono_right_tsfile)
        self.mono_rear_ts = read_ts_file(self.mono_rear_tsfile)
        self.stereo_ts = read_ts_file(self.stereo_tsfile)    

        self.split = split
        self.sampling_distance = sampling_distance
        
        # Maximum discrepancy between timestamps of LiDAR scan and global pose in seconds
        self.pose_time_tolerance = 1.

  
        self.pose_file = os.path.join(sequence_path, 'gps/ins.csv')
        assert os.path.exists(self.pose_file), f'Cannot access ground truth file: {self.pose_file}'

        self.rel_left_lidar_path = os.path.join(self.sequence_name, 'velodyne_left')
        left_lidar_path = os.path.join(self.dataset_root, self.rel_left_lidar_path)
        assert os.path.exists(left_lidar_path), f'Cannot access left lidar scans: {left_lidar_path}'

        self.pcim_loader = OxfordPointCloudWithImageLoader()

        timestamps, poses = read_lidar_poses(self.pose_file, left_lidar_path, self.pose_time_tolerance)
        self.xys = poses[:, :2, 3]
        self.timestamps, self.poses = self.filter(timestamps, poses)

        self.rel_scan_filepath = [os.path.join(self.rel_left_lidar_path, str(e) + '.bin') for e in self.timestamps]

        self.extrinsics_dir = os.path.join(self.dataset_root, 'extrinsics')
        filepaths = []
        pop_list = []
        for idx in range(len(self.rel_scan_filepath)):
            file_valid = self.get_filepaths(idx)
            if file_valid is None:
                pop_list.append(idx)
            else:
                filepaths.append(file_valid)
    
        self.filepaths = filepaths
        self.poses = np.delete(self.poses, pop_list, 0)
        print("raw data:", len(self.timestamps))
        self.timestamps = np.delete(self.timestamps, pop_list)
        
        self.rel_scan_filepath = np.delete(self.rel_scan_filepath, pop_list)
        print("valid data:", len(self.timestamps))
        assert len(self.timestamps) == len(self.poses)
        assert len(self.timestamps) == len(self.rel_scan_filepath)
        print(f'{len(self.timestamps)} scans in {sequence_name}-{split}')

    def __len__(self):
        return len(self.rel_scan_filepath)

    def __getitem__(self, ndx):
        filepaths = self.get_filepaths(ndx)
        pcs, images = self.pcim_loader(filepaths, extrinsics_dir=self.extrinsics_dir)

        return {'pc': pcs, 'img': images, 'pose': self.poses[ndx], 'ts': self.timestamps[ndx],
                'position': self.poses[ndx][:2, 3]}


    def get_filepaths(self, ndx):
        reading_left_lidar_filepath = os.path.join(self.dataset_root, self.rel_scan_filepath[ndx])
        timestamps = self.timestamps[ndx]

        right_lidar_ndx = find_nearest_ndx(timestamps, self.right_lidar_ts)
        mono_left_ndx = find_nearest_ndx(timestamps, self.mono_left_ts)
        mono_right_ndx = find_nearest_ndx(timestamps, self.mono_right_ts)
        mono_rear_ndx = find_nearest_ndx(timestamps, self.mono_rear_ts)
        stereo_ndx = find_nearest_ndx(timestamps, self.stereo_ts)
        
        right_lidar_timestamp = self.right_lidar_ts[right_lidar_ndx]
        mono_left_timestamp = self.mono_left_ts[mono_left_ndx]
        mono_right_timestamp = self.mono_right_ts[mono_right_ndx]
        mono_rear_timestamp = self.mono_rear_ts[mono_rear_ndx]
        stereo_timestamp = self.stereo_ts[stereo_ndx]

        reading_right_lidar_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'velodyne_right')
        reading_mono_left_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'mono_left_rect')
        reading_mono_right_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'mono_right_rect')
        reading_mono_rear_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'mono_rear_rect')
        reading_stereo_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'stereo/centre_rect')

        reading_mono_left_filepath = reading_mono_left_filepath.replace('bin', 'png')
        reading_mono_right_filepath = reading_mono_right_filepath.replace('bin', 'png')
        reading_mono_rear_filepath = reading_mono_rear_filepath.replace('bin', 'png')
        reading_stereo_filepath = reading_stereo_filepath.replace('bin', 'png')

        reading_right_lidar_filepath = reading_right_lidar_filepath.replace(str(timestamps), str(right_lidar_timestamp))
        reading_mono_left_filepath = reading_mono_left_filepath.replace(str(timestamps), str(mono_left_timestamp))
        reading_mono_right_filepath = reading_mono_right_filepath.replace(str(timestamps), str(mono_right_timestamp))
        reading_mono_rear_filepath = reading_mono_rear_filepath.replace(str(timestamps), str(mono_rear_timestamp))
        reading_stereo_filepath = reading_stereo_filepath.replace(str(timestamps), str(stereo_timestamp))

        filepaths = [reading_left_lidar_filepath, reading_right_lidar_filepath, reading_mono_left_filepath, reading_mono_right_filepath, reading_mono_rear_filepath, reading_stereo_filepath]

        return filepaths


    def load_pcs(self, scan_paths):
        # Load point cloud from file
        pcs = []
        for scan_path in scan_paths:
            pc = load_lidar_file_oxford_radar(scan_path)
            if len(pc) == 0:
                continue
            pcs.append(pc)
        pcs = np.array(pcs)
        return pcs 
        

    def filter(self, ts: np.ndarray, poses: np.ndarray):
        # Filter out scans - retain only scans within a given split with minimum displacement
        positions = poses[:, :2, 3]

        # Retain elements in the given split
        # Only sejong sequence has train/test split
        if self.split != 'all':
            if self.split == 'train':
                mask = in_train_split(positions)
            elif self.split == 'test':
                mask = in_test_split(positions)

            ts = ts[mask]
            poses = poses[mask]
            positions = positions[mask]
            print(f'Split: {self.split}   Mask len: {len(mask)}   Mask True: {np.sum(mask)}')

        # Filter out scans - retain only scans within a given split
        prev_position = None
        mask = []
        for ndx, position in enumerate(positions):
            if prev_position is None:
                mask.append(ndx)
                prev_position = position
            else:
                displacement = np.linalg.norm(prev_position - position)
                # print("displacement: ", displacement)
                if displacement > self.sampling_distance:
                    mask.append(ndx)
                    prev_position = position

        ts = ts[mask]
        poses = poses[mask]
        
        return ts, poses


class OxfordSequences(Dataset):
    """
    Multiple Oxford sequences indexed as a single dataset. Each element is identified by a unique global index.
    """
    def __init__(self, dataset_root: str, sequence_names: List[str], split: str, sampling_distance: float = 1.0):
        assert len(sequence_names) > 0
        assert os.path.exists(dataset_root), f'Cannot access dataset root: {dataset_root}'
        assert split in ['train', 'test', 'all']

        self.dataset_root = dataset_root
        self.sequence_names = sequence_names
        self.split = split
        self.sampling_distance = sampling_distance

        sequences = []
        for seq_name in self.sequence_names:
            ds = OxfordSequence(self.dataset_root, seq_name, split=split, sampling_distance=sampling_distance)
            sequences.append(ds)

        self.dataset = ConcatDataset(sequences)

        # Concatenate positions from all sequences
        self.poses = np.zeros((len(self.dataset), 4, 4), dtype=np.float64)
        self.timestamps = np.zeros((len(self.dataset),), dtype=np.int64)
        self.rel_scan_filepath = []
        self.filepaths = []
        self.seq_pose = []
        self.xys = self.poses[:, :2, 3]
        
        for cum_size, ds in zip(self.dataset.cumulative_sizes, sequences):
            # Consolidated lidar positions, timestamps and relative filepaths
            self.poses[cum_size - len(ds): cum_size, :] = ds.poses
            self.timestamps[cum_size - len(ds): cum_size] = ds.timestamps
            self.rel_scan_filepath.extend(ds.rel_scan_filepath)
            self.filepaths.extend(ds.filepaths)

        assert len(self.timestamps) == len(self.poses)
        assert len(self.timestamps) == len(self.rel_scan_filepath)

        # Build a kdtree based on X, Y position
        self.kdtree = KDTree(self.get_xy())

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, ndx):
        return self.dataset[ndx]

    def get_xy(self):
        # Get X, Y position from (4, 4) pose
        return self.poses[:, :2, 3]

    def load_pcs(self, scan_paths):
        # Load point cloud from file
        pcs = []
        for scan_path in scan_paths:
            pc = load_lidar_file_oxford_radar(scan_path)
            if len(pc) == 0:
                continue
            pcs.append(pc)
        pcs = np.array(pcs)
        return pcs 

    def find_neighbours_ndx(self, position, radius):
        # Returns indices of neighbourhood point clouds for a given position
        assert position.ndim == 1
        assert position.shape[0] == 2
        # Reshape into (1, 2) axis
        position = position.reshape(1, -1)
        neighbours = self.kdtree.query_radius(position, radius)[0]
        random.shuffle(neighbours)

        return neighbours.astype(np.int32)


if __name__ == '__main__':
    dataset_root = '~/Data/Oxford_radar/'
    sequence_names = ['2019-01-11-13-24-51']

    db = OxfordSequences(dataset_root, sequence_names, split='train')
    print(f'Number of scans in the sequence: {len(db)}')
    e = db[0]

    res = db.find_neighbours_ndx(e['position'], radius=50)
    print('.')

